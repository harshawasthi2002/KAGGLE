{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/harshawasthi3167/deep-learning-cyclesheet3-part2?scriptVersionId=209052299\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **DEEP LEARNING LAB CYCLE SHEET -2 PART2**\n\n# **NAME :- HARSH AWASTHI**\n\n# **REG NO :- 21BDS0196**\n\n# [LINK TO KAGGLE NOTEBOOK](https://www.kaggle.com/code/harshawasthi3167/deep-learning-cyclesheet3-part2)","metadata":{}},{"cell_type":"markdown","source":"#4\n\nYour task is to build and fine-tune a BERT base model to classify each review as either positive or \r\nnegative. (Consider the use case given in the previous question) \r\n Load the pre-trained BERT base model. \r\n Add a classification layer on top of BERT for binary classification. \r\n Fine-tune the BERT model on the prepared dataset. \r\n Use binary cross-entropy as the loss function and an appropriate optimizer (e.g., AdamW). \r\n Evaluate the model’s performance on the test data. \r\n Calculate the accuracy and other relevant metrics. \r\n Use the trained model to predict the sentiment of new reviews, e.g., “The plot was dull and \r\nuninteresting.” ","metadata":{}},{"cell_type":"code","source":"pip install transformers torch scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:45:42.847224Z","iopub.execute_input":"2024-11-22T16:45:42.847601Z","iopub.status.idle":"2024-11-22T16:45:54.87611Z","shell.execute_reply.started":"2024-11-22T16:45:42.847565Z","shell.execute_reply":"2024-11-22T16:45:54.874646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Load the pre-trained BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:45:54.878708Z","iopub.execute_input":"2024-11-22T16:45:54.879213Z","iopub.status.idle":"2024-11-22T16:46:04.594382Z","shell.execute_reply.started":"2024-11-22T16:45:54.879158Z","shell.execute_reply":"2024-11-22T16:46:04.593285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass ReviewDataset(Dataset):\n    def __init__(self, reviews, labels):\n        self.reviews = reviews\n        self.labels = labels\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.reviews)\n\n    def __getitem__(self, idx):\n        review = self.reviews[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer.encode_plus(\n            review,\n            add_special_tokens=True,\n            max_length=128,\n            return_token_type_ids=False,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt',\n            truncation=True\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Example usage\nreviews = [\"The movie was great!\", \"The plot was dull and uninteresting.\"]\nlabels = [1, 0]  # 1 for positive, 0 for negative\ndataset = ReviewDataset(reviews, labels)\ndataloader = DataLoader(dataset, batch_size=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:46:04.596669Z","iopub.execute_input":"2024-11-22T16:46:04.597296Z","iopub.status.idle":"2024-11-22T16:46:04.606668Z","shell.execute_reply.started":"2024-11-22T16:46:04.597245Z","shell.execute_reply":"2024-11-22T16:46:04.605434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AdamW\nfrom tqdm import tqdm\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\n# Training loop\nmodel.train()\nfor epoch in range(3):  # Number of epochs\n    for batch in tqdm(dataloader):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:46:04.764659Z","iopub.execute_input":"2024-11-22T16:46:04.764958Z","iopub.status.idle":"2024-11-22T16:46:13.31051Z","shell.execute_reply.started":"2024-11-22T16:46:04.764927Z","shell.execute_reply":"2024-11-22T16:46:13.309381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example test data\ntest_reviews = [\"The movie was amazing!\", \"I didn't enjoy the movie at all.\"]\ntest_labels = [1, 0]  # 1 for positive, 0 for negative\n\n# Create a dataset for the test data\ntest_dataset = ReviewDataset(test_reviews, test_labels)\n\n# Create DataLoader for the test dataset\ntest_dataloader = DataLoader(test_dataset, batch_size=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:48:02.525132Z","iopub.execute_input":"2024-11-22T16:48:02.525524Z","iopub.status.idle":"2024-11-22T16:48:02.531834Z","shell.execute_reply.started":"2024-11-22T16:48:02.525485Z","shell.execute_reply":"2024-11-22T16:48:02.530458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Initialize lists for storing predictions and true labels\npredictions, true_labels = [], []\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Evaluate the model on the test dataset\nfor batch in test_dataloader:\n    with torch.no_grad():\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        # Get predictions\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        true_labels.extend(labels.cpu().numpy())\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(true_labels, predictions)\nprint(f'Accuracy: {accuracy}')\nprint(classification_report(true_labels, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:47:43.714203Z","iopub.execute_input":"2024-11-22T16:47:43.714615Z","iopub.status.idle":"2024-11-22T16:47:44.478083Z","shell.execute_reply.started":"2024-11-22T16:47:43.714575Z","shell.execute_reply":"2024-11-22T16:47:44.476826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_sentiment(review):\n    model.eval()\n    inputs = tokenizer.encode_plus(\n        review,\n        add_special_tokens=True,\n        max_length=128,\n        return_tensors='pt',\n        padding='max_length',\n        truncation=True\n    )\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        prediction = torch.argmax(logits, dim=1).item()\n    \n    return \"Positive\" if prediction == 1 else \"Negative\"\n\n# Example usage\nnew_review = \"The plot was dull and uninteresting.\"\nsentiment = predict_sentiment(new_review)\nprint(f'Sentiment: {sentiment}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T16:49:15.978679Z","iopub.execute_input":"2024-11-22T16:49:15.979057Z","iopub.status.idle":"2024-11-22T16:49:16.26086Z","shell.execute_reply.started":"2024-11-22T16:49:15.979022Z","shell.execute_reply":"2024-11-22T16:49:16.259865Z"}},"outputs":[],"execution_count":null}]}